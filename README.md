

# MultiTalk for RunPod Serverless (Optimized)

[ÌïúÍµ≠Ïñ¥ README Î≥¥Í∏∞](README_kr.md)

This project is an **optimized template** designed to easily deploy and use [MeiGen-AI/MultiTalk](https://github.com/MeiGen-AI/MultiTalk) in the RunPod Serverless environment.

> **üöÄ Enhancements in this version:**
> *   **Instant Cold Starts**: Model weights (~20GB) are baked into the Docker image, reducing startup time from 30+ minutes to seconds.
> *   **H100 & Future-Proof Support**: Updated environment (CUDA 12.4 + PyTorch 2.5.1) to support **NVIDIA H100**, **RTX 4090**, and **RTX 5090**.
> *   **Universal Compatibility**: Runs on T4, V100, A100, A6000, and more.

MultiTalk is an AI model that takes a single portrait image and multilingual speech audio as input to generate natural lip-sync videos in real-time.

## ‚ú® Key Features

*   **Multilingual Support**: Processes speech in various languages and reflects it in the video.
*   **Real-time Video Generation**: Creates videos synchronized with input audio at high speed.
*   **High-Quality Lip-sync**: Lip movements are precisely synchronized with the input audio.

## üöÄ Deployment Guide

To deploy this on RunPod, please follow the detailed step-by-step guide:

üëâ **[Read the DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md)**

This guide covers:
1.  Pushing the code to your GitHub.
2.  Building the optimized Docker images.
3.  Setting up the Serverless Endpoint on RunPod.

## üõ†Ô∏è Usage and API Reference

### Input

The `input` object must contain the following fields. `image_path` and `audio_paths` support **URL, file path, or Base64 encoded string**.

| Parameter | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `prompt` | `string` | **Yes** | `N/A` | Description text for the video to be generated. |
| `image_path` | `string` | **Yes** | `N/A` | Path, URL, or Base64 string of the portrait image to apply lip-sync to. |
| `audio_paths` | `object` | **Yes** | `N/A` | Map of audio files in the format `{ "person1": "audio_path/URL/Base64" }`, or `{ "person1": "audio_path/URL/Base64", "person2": "audio_path/URL/Base64" }` |


**Request Example:**

```json
{
  "input": {
    "prompt": "A person is talking in a natural way.",
    "image_path": "https://path/to/your/portrait.jpg",
    "audio_paths": {
      "person1": "data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQAAAAA="
    }
  }
}
```

### Output

#### Success

If the job is successful, it returns a JSON object with the generated video Base64 encoded.

| Parameter | Type | Description |
| --- | --- | --- |
| `status` | `string` | Returns `"success"`. |
| `video_base64` | `string` | Base64 encoded video file data. |
| `filename` | `string` | Name of the generated video file (excluding `.mp4` extension). |

**Success Response Example:**

```json
{
  "status": "success",
  "video_base64": "...",
  "filename": "generated_video"
}
```

#### Error

If the job fails, it returns a JSON object containing an error message.

| Parameter | Type | Description |
| --- | --- | --- |
| `error` | `string` | Description of the error that occurred. |
| `stdout` | `string` | (Optional) Standard output logs generated during script execution. |
| `stderr` | `string` | (Optional) Standard error logs generated during script execution. |

**Error Response Example:**

```json
{
  "error": "Failed to execute generate_multitalk.py script",
  "stdout": "...",
  "stderr": "..."
}
```

### üìÅ Using Network Volumes

Instead of directly transmitting Base64 encoded files, you can use RunPod's Network Volumes to handle large files. This is especially useful when dealing with large image or audio files.

1.  **Create and Connect Network Volume**: Create a Network Volume (e.g., S3-based volume) from the RunPod dashboard and connect it to your Serverless Endpoint settings.
2.  **Upload Files**: Upload the image and audio files you want to use to the created Network Volume.
3.  **Specify Paths**: When making an API request, specify the file paths within the Network Volume for `image_path` and `audio_paths`. For example, if the volume is mounted at `/my_volume` and you use `portrait.jpg`, the path would be `"/my_volume/portrait.jpg"`.

### Usage Example (Python)

This example is based on the code in `single_examples.ipynb`.

#### 1. Configuration

```python
import os
import requests
import json
import boto3
from botocore.client import Config
import time
import base64

# RunPod Serverless API Information
ENDPOINT_ID = ""    # Replace with your actual serverless endpoint ID
RUN_URL = f"https://api.runpod.ai/v2/{ENDPOINT_ID}/run"
RUNPOD_API_ENDPOINT = f"https://api.runpod.ai/v2/{ENDPOINT_ID}/run"
RUNPOD_API_KEY = '' # Replace with your actual key

# RunPod Network Volume S3 Information (Check RunPod Dashboard) Adjust to your actual settings
S3_ENDPOINT_URL = 'https://s3api-eu-ro-1.runpod.io/'  # e.g., https://us-east-1.runpod.cloud
S3_ACCESS_KEY_ID = ''
S3_SECRET_ACCESS_KEY = ''
S3_BUCKET_NAME = '' 
S3_REGION = ''

# Local file paths to upload
IMAGE_PATH = ""
AUDIO_PATH = ""

# File names to be uploaded to S3 (can include path)
S3_IMAGE_KEY = f"input/multitalk/{os.path.basename(IMAGE_PATH)}"
S3_AUDIO_KEY = f"input/multitalk/{os.path.basename(AUDIO_PATH)}"
```

#### 2. Upload Files to S3

```python
def upload_to_s3(file_path, bucket, object_name):
    """Uploads the specified file to S3-compatible storage."""
    print(f"Creating S3 client... (Endpoint: {S3_ENDPOINT_URL})")
    s3_client = boto3.client(
        's3',
        endpoint_url=S3_ENDPOINT_URL,
        aws_access_key_id=S3_ACCESS_KEY_ID,
        aws_secret_access_key=S3_SECRET_ACCESS_KEY,
        region_name=S3_REGION,
        config=Config(signature_version='s3v4')
    )
    
    try:
        print(f"Starting upload of '{file_path}' to S3 bucket '{bucket}' as '{object_name}'...")
        s3_client.upload_file(file_path, bucket, object_name)
        print(f"‚úÖ File upload successful: s3://{bucket}/{object_name}")
        return f"/runpod-volume/{object_name}"
    except Exception as e:
        print(f"‚ùå File upload failed: {e}")
        return None

# Check if files exist
if not all(map(os.path.exists, [IMAGE_PATH, AUDIO_PATH])):
    raise FileNotFoundError("Check input file paths. Files do not exist.")

# Upload each file to S3
image_s3_path = upload_to_s3(IMAGE_PATH, S3_BUCKET_NAME, S3_IMAGE_KEY)
audio_s3_path = upload_to_s3(AUDIO_PATH, S3_BUCKET_NAME, S3_AUDIO_KEY)

if not all([image_s3_path, audio_s3_path]):
    raise RuntimeError("S3 file upload failed, stopping operation.")
```

#### 3. Submit Job Request

```python
# HTTP Request Headers
headers = {
    "Authorization": f"Bearer {RUNPOD_API_KEY}",
    "Content-Type": "application/json"
}

# Data to send to the API (using S3 paths instead of Base64)
# Important: The server's handler code must be modified to expect keys like 'cond_image_s3_path'.
payload = {
    "input": {
        "prompt": "a man talking",
        "image_path": image_s3_path,
        "audio_paths": {
            "person1": audio_s3_path
        }
    }
}

# Send POST request to the API
print(f"\nüöÄ Submitting job to RunPod Serverless endpoint [{RUNPOD_API_ENDPOINT}]...")
try:
    response = requests.post(RUNPOD_API_ENDPOINT, headers=headers, json=payload)
    response.raise_for_status()  # Raise an error for bad status codes (4xx or 5xx)

    # Check response
    print("‚úÖ Request successful!")
    print(f"üìÑ Status Code: {response.status_code}")
    
    response_data = response.json()
    print("\n[RunPod API Response Content]")
    print(json.dumps(response_data, indent=4))
    
    job_id = response_data.get('id')
    print(f"\n‚ú® Job successfully submitted. Job ID: {job_id}")
    print("You can check the result via the /status endpoint.")

except requests.exceptions.HTTPError as errh:
    print(f"‚ùå HTTP Error occurred: {errh}")
    print(f"Response content: {errh.response.text}")
except requests.exceptions.RequestException as err:
    print(f"‚ùå Error during request: {err}")
```

#### 4. Check Result

```python
job_output = None

STATUS_URL = f"https://api.runpod.ai/v2/{ENDPOINT_ID}/status"
while True:
    print(f"‚è±Ô∏è Checking job status... (Job ID: {job_id})")
    status_response = requests.get(f"{STATUS_URL}/{job_id}", headers=headers)
    status_response.raise_for_status()
    
    status_data = status_response.json()
    status = status_data.get('status')
    
    if status == 'COMPLETED':
        print("‚úÖ Job completed!")
        job_output = status_data.get('output')
        break
    elif status == 'FAILED':
        print("‚ùå Job failed.")
        job_output = status_data.get('error', 'Unknown error')
        break
    elif status in ['IN_QUEUE', 'IN_PROGRESS']:
        print(f"üèÉ Job in progress... (Status: {status})")
        time.sleep(5)  # Wait 5 seconds and check again
    else:
        print(f"‚ùì Unknown status: {status}")
        job_output = status_data
        break

# --- Part 3: Download and Decode Result ---
if job_output and status == 'COMPLETED':
    # You may need to adjust the 'video_b64' key depending on the handler's return value.
    video_b64 = job_output.get('video_base64')
    
    if video_b64:
        print("üé® Decoding and saving result to file...")
        try:
            decoded_video = base64.b64decode(video_b64)
            output_filename = f"./result_{job_id}.mp4" # change path
            
            with open(output_filename, 'wb') as f:
                f.write(decoded_video)
                
            print(f"‚ú® Final result saved to '{output_filename}'!")
        except Exception as e:
            print(f"‚ùå Error decoding or saving result: {e}")
    else:
        print("‚ö†Ô∏è Result (video_b64) not returned. Check handler's return value.")
elif status == 'FAILED':
        print(f"Failure reason: {job_output}")
```



## üôè Original Project

This project is based on the following original repository. All rights to the model and core logic belong to the original authors.

*   **MeiGen-AI/MultiTalk:** [https://github.com/MeiGen-AI/MultiTalk](https://github.com/MeiGen-AI/MultiTalk)

## üìÑ License

The original MultiTalk project follows the Apache 2.0 License. This template also adheres to that license.
